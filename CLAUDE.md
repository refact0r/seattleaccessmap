# DubsTech Datathon Project: City Accessibility Analysis

## Overview

Hackathon project using the **Project Sidewalk Seattle Accessibility Dataset** (~82k crowdsourced observations of sidewalk conditions). The goal is to both analyze the data, create a map visualization, and most importantly to build a routing tool that finds alternative accessible paths that minimize exposure to accessibility barriers for people with mobility challenges.

Hackathon prompt: `reference/access-to-everyday-life.md`. We're deviating a little from the prompt's questions (we just want to make a cool project) but still addressing the core themes.

## Dataset

- **Location:** `data/Access_to_Everyday_Life_Dataset.csv`
- **Records:** 81,973
- **Records missing 'severity':** 2,251 (2.7%) — rows with no severity rating, dropped for clustering/severity analysis
- **Columns (renamed in code):**
  - `lng`, `lat` — coordinates
  - `id` — unique observation ID (`properties/attribute_id`)
  - `label_type` — 7 types: `CurbRamp`, `NoCurbRamp`, `NoSidewalk`, `Obstacle`, `Occlusion`, `SurfaceProblem`, `Other`
  - `neighborhood` — 50 neighborhoods
  - `severity` — 1-5 scale (float, some NaN)
  - `is_temporary` — boolean
- **No other data quality issues found.** Coordinates are clean, types are consistent.

## What's Been Built

### `analysis.py`

Single script that runs end-to-end. Outputs go to `output/`.

**Sections:**

1. **Load & Clean** — Reads CSV, renames columns, drops constant cols (`type`, `geometry/type`), converts types. Creates `df_with_sev` (rows with severity) for analysis.
2. **Basic EDA** — 4-panel chart: issue type distribution, severity distribution, top 15 neighborhoods, mean severity by type. → `eda_overview.png`
3. **Neighborhood severity heatmap** — Top 20 neighborhoods × label type mean severity matrix. → `neighborhood_severity_heatmap.png`
4. **HDBSCAN clustering** — Filters to severity >= 3 (47,466 points). Uses haversine metric on radians. Leaf selection for street-level granularity. → 2,349 clusters, ~35k clustered points, ~13k noise.
5. **Cluster summary** — Per-cluster stats: count, mean/max severity, type breakdown (`n_<type>` columns), spatial spread (meters), neighborhood, centroid. Hotspot score = count × mean_severity × type diversity bonus (15% per additional type). → `cluster_summary.csv`
6. **Scatter plot** — All clusters colored, noise in gray. → `hdbscan_clusters.png`
7. **Export data for web map** — Exports JSON data files for visualization. Hotspot clusters with individual points, metadata, and heatmap data. → `clusters_data.json` (145KB) + `heatmap_data.json` (2.1MB)
8. **Temp vs permanent chart** — Stacked bar of permanent vs temporary issues by type. → `temp_vs_permanent.png`

### Interactive Map Architecture

The web map uses a **clean separation between code and data**:

**Files:**

- `index.html` — Static HTML template with Leaflet.js visualization code. NOT generated by Python.
- `output/clusters_data.json` (109KB) — 30 metadata + all point coordinates per cluster. Generated by Python.
- `output/heatmap_data.json` (2.1MB) — All 47k+ severe issue points with [lat, lng, severity] for heatmap layer. Generated by Python.

**Benefits:**

- Complete separation: Python generates data, HTML visualizes it
- HTML can be edited directly without touching Python code
- JSON data can be inspected, reused, or consumed by other tools
- Async loading with fetch API — map renders progressively
- Uses native Leaflet instead of Folium for more control and modern UX

**Features:**

- Severity heatmap toggle (all severe issues)
- Cluster layers (individually toggleable)
- Popup markers with full type breakdown on click
- Clean info panel with instructions
- Responsive full-screen layout

### HDBSCAN Parameters & Rationale

```python
hdbscan.HDBSCAN(
    min_cluster_size=8,    # a bad block may have just 8-15 issues
    min_samples=5,         # require genuine local density
    metric="haversine",    # proper distance on lat/lng
    cluster_selection_method="leaf",  # finest-grained clusters
)
```

- **Why leaf selection:** Default EOM method produced neighborhood-scale blobs (411 huge clusters) or collapsed everything into 2 mega-clusters with epsilon. Leaf selection forces the most granular splits — produces street/block-level clusters (typical spread 150-400m).
- **Why severity >= 3 filter:** Focuses clustering on genuinely problematic areas rather than diluting with low-severity observations.
- **Hotspot score formula:** `count * mean_severity * (1 + 0.15 * (n_types - 1))` — rewards areas with compounding multi-type failures.

### Key Findings So Far

- **NoSidewalk** dominates the worst hotspots
- **Industrial District** has the most clusters in the top 20 (6+)
- **Whittier Heights** cluster #546 has **perfect 5.0 mean severity** across 57 points
- Multi-type clusters (3-5 barrier types in one area) surface in Industrial District, Wallingford, Windermere, Ravenna
- Most issues are permanent, not temporary

## Dependencies

**Python (analysis script):**

```
pandas numpy scikit-learn hdbscan matplotlib seaborn
```

All installed via pip3 into system Python 3.9.

**Web map (loaded via CDN in HTML):**

- Leaflet.js 1.9.4 — core mapping library
- leaflet.heat 0.2.0 — heatmap layer plugin

## Running

```bash
python3 analysis.py
```

Outputs regenerate into `output/`. Takes ~30 seconds (HDBSCAN is the slow part).

## Viewing the Interactive Map

The HTML map requires a local web server (browsers block JSON loading from `file://` due to CORS):

```bash
./serve.sh
# Or: python3 -m http.server 8000
```

Then open: **<http://localhost:8000/index.html>**

## Output Files

### Static Visualizations (open directly)

- `eda_overview.png` — Basic exploratory analysis: issue types, severity, neighborhoods
- `neighborhood_severity_heatmap.png` — Top 20 neighborhoods by severity and type
- `hdbscan_clusters.png` — Scatter plot of all clusters
- `temp_vs_permanent.png` — Permanent vs temporary issues breakdown

### Data Files

- `cluster_summary.csv` — All 2,349 cluster statistics (ranked by hotspot score)
- `clusters_data.json` — Cluster metadata + point coordinates (109KB)
- `heatmap_data.json` — All 47k severe issues for heatmap layer (2.1MB)

### Interactive Map

- `index.html` — Leaflet-based web map (requires local server, see above)
